{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def umlaut(string):\n",
    "    if not isinstance(string, str):\n",
    "        raise TypeError(\"The oject is a \" + str(type(string)) + \", not a string!\")\n",
    "    string = string.replace(\"Ã¼\", \"ü\")\n",
    "    string = string.replace(\"Ã¤\", \"ä\")    \n",
    "    string = string.replace(\"Ã¶\", \"ö\")    \n",
    "    string = string.replace(\"Ãœ\", \"Ü\")    \n",
    "    string = string.replace(\"Ã„\", \"Ä\")    \n",
    "    string = string.replace(\"Ã–\", \"Ö\")    \n",
    "    string = string.replace(\"ÃŸ\", \"ß\")    \n",
    "    return string\n",
    "\n",
    "def replace_umlauts(dictionary):\n",
    "    try:\n",
    "        dictionary = umlaut(dictionary)\n",
    "    except TypeError:\n",
    "        copy = dictionary\n",
    "        try:\n",
    "            iteritems = dictionary.items()\n",
    "        except AttributeError:\n",
    "            iteritems = enumerate(dictionary)\n",
    "        for k, v in iteritems:\n",
    "            copy[k] = replace_umlauts(v)\n",
    "        dictionary = copy\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('paths.json') as f:\n",
    "    data = json.load(f)\n",
    "    data = replace_umlauts(data)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywordFile = data['keywords']['file']\n",
    "keywordFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDirs = data['data']['directory']\n",
    "dataDirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testFile = data['data']['test']\n",
    "testFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords\n",
    "Keywords are in a table in a MS word document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the first table of the docx file\n",
    "\n",
    "from docx import Document\n",
    "document = Document(keywordFile)\n",
    "table = document.tables[0]\n",
    "text = []\n",
    "for i in range(len(table.rows)):\n",
    "    text.append([])\n",
    "    for j in range(len(table.columns)):\n",
    "        text[i].append(table.rows[i].cells[j].text)\n",
    "        \n",
    "# remove header\n",
    "text = text[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split in English and German\n",
    "text_en = list(map(lambda x: x[2:4], text))\n",
    "text_de = list(map(lambda x: x[0:2], text))\n",
    "text_de[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_dict(text):\n",
    "    dictionary = {}\n",
    "    i = 0\n",
    "    key = ''\n",
    "    for row in text:\n",
    "        word = row[0]\n",
    "        veto = row[1]\n",
    "        if word != '':\n",
    "            key = word\n",
    "            dictionary[key] = []\n",
    "        if veto != '':\n",
    "            dictionary[key].append(veto)\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dictionary of pairwise keywords and vetoes\n",
    "keywords_de = produce_dict(text_de)\n",
    "keywords_en = produce_dict(text_en)\n",
    "keywords_de[next(iter(keywords_de))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documents\n",
    "\n",
    "Documents are drawn from URLs in MS Outlook files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import win32com.client\n",
    "import os\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "\n",
    "outlook = win32com.client.Dispatch(\"Outlook.Application\").GetNamespace(\"MAPI\")\n",
    "\n",
    "URLs = []\n",
    "maxMails = 200\n",
    "openMails = 0\n",
    "for directory in dataDirs:\n",
    "    for filename in os.listdir(directory):\n",
    "        openMails += 1\n",
    "        if openMails > maxMails:\n",
    "            break\n",
    "        filePath = os.path.abspath(os.path.join(directory, filename))\n",
    "        msg = outlook.OpenSharedItem(filePath)\n",
    "#         print(msg.SenderName)\n",
    "#         print(msg.Body)\n",
    "        matchObj = re.findall(r'<(.*?)>', msg.Body)\n",
    "        matchObj = list(OrderedDict.fromkeys(matchObj))  # remove duplicates\n",
    "        matchObj = [link for link in matchObj if not 'alerts' in link]\n",
    "        if matchObj:\n",
    "            print(filePath + \" : \" + str(len(matchObj)) + \" links\")\n",
    "            for index, element in enumerate(matchObj):\n",
    "#                 print(str(index) + \": \" + element)\n",
    "                URLs.append(element)\n",
    "\n",
    "        else:\n",
    "            print(\"No match!\")\n",
    "\n",
    "outlook.OpenSharedItem(os.path.abspath(os.path.join(dataDirs[0], testFile)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Found {} URLs'.format(len(URLs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Follow links and extract article text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4.element import Comment\n",
    "\n",
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]', 'footer', 'a']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    if (element.parent.name.strip() == element.strip()):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def extract_info(soup):\n",
    "    texts = soup.findAll(text=True)\n",
    "    visible_texts = filter(tag_visible, texts)\n",
    "    visible_texts = filter(lambda t: t.strip(), visible_texts)\n",
    "#     for text in visible_texts:\n",
    "#         print(str(text.parent) + ' : ' + text)\n",
    "    return [t.strip() for t in visible_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import functools\n",
    "\n",
    "maxURLs = 1000\n",
    "data = []\n",
    "exceptions = []\n",
    "\n",
    "for index, URL in enumerate(tqdm(URLs[0:])):\n",
    "    if index >= maxURLs:\n",
    "        break\n",
    "    # get googleLink\n",
    "    try:\n",
    "        r = requests.get(URL)\n",
    "    except requests.exceptions.MissingSchema as e: \n",
    "        exceptions.append([e, URL])\n",
    "    except Exception as e:\n",
    "        print('Exception ' + type(e).__name__ + \" in google URL\" + URL)\n",
    "        exceptions.append([e, URL])\n",
    "    result = re.search('URL=(.*?)\"', r.text)\n",
    "    try:\n",
    "        articleURL = result.group(1) \n",
    "    except AttributeError:\n",
    "        continue\n",
    "#     print(index, articleURL)\n",
    "    # follow redirect to get final article\n",
    "    try:\n",
    "        r = requests.get(articleURL)\n",
    "    except requests.exceptions.MissingSchema as e: \n",
    "        exceptions.append([e, articleURL])\n",
    "    except Exception as e:\n",
    "        print('Exception ' + type(e).__name__ + \" in article URL \" + articleURL)\n",
    "        exceptions.append([e, articleURL])\n",
    "    soup = BeautifulSoup(r.text, 'html5lib')\n",
    "    text = extract_info(soup)\n",
    "    if not text:\n",
    "        continue\n",
    "    # restrict to text around longest continous entry\n",
    "    # TODO: improve this to cut away more junk\n",
    "    longest = text.index(max(text, key=len))\n",
    "    margin = 10\n",
    "    minIdx = max(longest - margin, 0)\n",
    "    maxIdx = min(longest + margin, len(text)-1)\n",
    "    text = text[minIdx:maxIdx]\n",
    "    text = functools.reduce(lambda x, y : x + ' ' + y, text, \"\")\n",
    "    #     print(*text, sep='\\n\\n')\n",
    "    data.append({'text': text, 'URL': articleURL})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write data on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"articles.h5\")\n",
    "# read with df = pd.read_pickle(file_name)\n",
    "# for very quick acces use HDF5 (PyTables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
